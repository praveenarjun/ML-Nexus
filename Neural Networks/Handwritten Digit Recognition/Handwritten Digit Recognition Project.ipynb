{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a2e435f-211f-4a69-ae5a-42f0cb4513d0",
   "metadata": {},
   "source": [
    "# Handwritten Digit Recognition Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77ae9ad-35e9-4d44-bc2f-2205353fe473",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The Handwritten Digit Recognition project aims to accurately identify and classify handwritten digits, a challenge that is crucial for various applications such as automated data entry and postal services. The variability in handwriting styles can significantly impact recognition accuracy. This project utilizes the MNIST dataset, which contains a vast collection of handwritten digits, to develop a robust neural network model using TensorFlow and Keras.\n",
    "\n",
    "## Problem Statement\n",
    "Accurately recognizing handwritten digits is essential for many automated systems. The variability in handwriting styles creates a significant challenge for traditional recognition methods, leading to decreased accuracy. By leveraging the MNIST dataset, this project seeks to develop a neural network that can effectively learn to distinguish between different handwritten digits, improving its ability to generalize and make accurate predictions on unseen data.\n",
    "\n",
    "## Proposed Solution\n",
    "The proposed solution involves developing a Convolutional Neural Network (CNN) model that leverages TensorFlow and Keras for digit classification. The solution will consist of several key components:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17068820-7796-4036-908d-a21b3ece6f0f",
   "metadata": {},
   "source": [
    "## Step 1: **Set Up Your Environment**\n",
    "Install Required Libraries Make sure you have Python and the necessary libraries installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db1f7ff9-bc51-402f-b885-9345a3aa7469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\asus\\anaconda3\\lib\\site-packages (2.16.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\asus\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\asus\\anaconda3\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (23.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.16.2->tensorflow)\n",
      "  Downloading protobuf-4.25.5-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.66.2)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.2->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: rich in c:\\users\\asus\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\asus\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\asus\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (0.1.0)\n",
      "Downloading protobuf-4.25.5-cp310-abi3-win_amd64.whl (413 kB)\n",
      "   ---------------------------------------- 0.0/413.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/413.4 kB ? eta -:--:--\n",
      "    --------------------------------------- 10.2/413.4 kB ? eta -:--:--\n",
      "   -- ------------------------------------ 30.7/413.4 kB 435.7 kB/s eta 0:00:01\n",
      "   -------- ------------------------------ 92.2/413.4 kB 655.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  409.6/413.4 kB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 413.4/413.4 kB 2.3 MB/s eta 0:00:00\n",
      "Installing collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.28.2\n",
      "    Uninstalling protobuf-5.28.2:\n",
      "      Successfully uninstalled protobuf-5.28.2\n",
      "Successfully installed protobuf-4.25.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\google\\~upb'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "grpcio-status 1.66.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.5 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow numpy matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a8b516-4e19-4aab-99a7-9d948731c6c0",
   "metadata": {},
   "source": [
    "## Step 2: **Import Libraries**\n",
    "Start your Python script or Jupyter Notebook by importing the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "718fa824-75a8-4629-bf49-722cb2936a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2099298c-a062-4054-9c39-0c639a958609",
   "metadata": {},
   "source": [
    "## Step 3: **Load the MNIST Dataset**\n",
    "The MNIST dataset is included in Keras, making it easy to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7bafa2f-a767-46ef-a0c7-5db59fc58a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "# Split into training and testing data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918b5d03-0b67-43bf-b546-01df024accca",
   "metadata": {},
   "source": [
    "## Step 4: **Preprocess the Data**\n",
    "Normalize the pixel values to be between 0 and 1 and reshape the input data for the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1d20c1e-81c6-4b69-ab20-b85b5f69fe65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (60000, 28, 28, 1), Test shape: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Normalize the images\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Reshape to add channel dimension (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "# Check the shape\n",
    "print(f\"Train shape: {x_train.shape}, Test shape: {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d4c617-48b3-44c1-8fa7-6dd11584cff5",
   "metadata": {},
   "source": [
    "## Step 5: **Define the CNN Model**\n",
    "Create a Convolutional Neural Network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d143304-2d9e-4aa1-ad0a-a01f3671bfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')  # 10 classes for digits 0-9\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf6f7f2-92be-48b2-937e-d4cc3866df99",
   "metadata": {},
   "source": [
    "## Step 6: **Compile the Model**\n",
    "Compile the model with an optimizer, loss function, and evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9f546e4-93fe-4b55-9522-2fb6a291c00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb54d5ee-325e-4ba8-9536-e03ad1c5cee5",
   "metadata": {},
   "source": [
    "## Step 7: **Train the Model**\n",
    "Train the model using the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "178289a7-10a8-4168-b2b2-95c5f8ab5dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.9046 - loss: 0.3278 - val_accuracy: 0.9808 - val_loss: 0.0684\n",
      "Epoch 2/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9858 - loss: 0.0477 - val_accuracy: 0.9836 - val_loss: 0.0490\n",
      "Epoch 3/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9905 - loss: 0.0312 - val_accuracy: 0.9883 - val_loss: 0.0379\n",
      "Epoch 4/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - accuracy: 0.9924 - loss: 0.0226 - val_accuracy: 0.9895 - val_loss: 0.0387\n",
      "Epoch 5/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - accuracy: 0.9949 - loss: 0.0151 - val_accuracy: 0.9880 - val_loss: 0.0438\n",
      "Epoch 6/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9953 - loss: 0.0130 - val_accuracy: 0.9864 - val_loss: 0.0489\n",
      "Epoch 7/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9976 - loss: 0.0072 - val_accuracy: 0.9906 - val_loss: 0.0371\n",
      "Epoch 8/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - accuracy: 0.9974 - loss: 0.0078 - val_accuracy: 0.9902 - val_loss: 0.0453\n",
      "Epoch 9/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9985 - loss: 0.0052 - val_accuracy: 0.9909 - val_loss: 0.0443\n",
      "Epoch 10/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9979 - loss: 0.0070 - val_accuracy: 0.9883 - val_loss: 0.0521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2c0b6f28dd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69104ec9-e539-4d8b-a9c1-caaa3239445d",
   "metadata": {},
   "source": [
    "## Step 8: **Evaluate the Model**\n",
    "Evaluate the model’s performance on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f55f3ef2-5fcc-4d3a-987b-42d2347551bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 2s - 7ms/step - accuracy: 0.9883 - loss: 0.0488\n",
      "Test accuracy: 0.9883000254631042\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7757b6b7-8b09-4ece-afb1-2392f463373b",
   "metadata": {},
   "source": [
    "## Step 9:**Make Predictions**\n",
    "Use the model to make predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46cfe0fb-a399-44da-b41c-f4e1bb5c2555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "\n",
    "# Display a sample prediction\n",
    "index = 0  # Change this index to see different predictions\n",
    "plt.imshow(x_test[index].reshape(28, 28), cmap='gray')\n",
    "plt.title(f\"Predicted: {np.argmax(predictions[index])}, Actual: {y_test[index]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f701e601-33bb-4016-8058-599f0dbc733b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('handwritten_digit_recognition_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0822aa-522a-49c4-a5f0-695392a95032",
   "metadata": {},
   "source": [
    "## Alternatives Considered\n",
    "Several alternative approaches were considered in the development of the Handwritten Digit Recognition project:\n",
    "\n",
    "- **Traditional Machine Learning Algorithms**: Algorithms such as Support Vector Machines (SVM) and k-Nearest Neighbors (k-NN) were considered for digit classification. While these methods can be effective for smaller datasets, they often struggle to generalize well with the complexity and variability inherent in handwritten digits compared to deep learning approaches.\n",
    "\n",
    "## Conclusion\n",
    "The implementation of a CNN for handwritten digit recognition showcases the effectiveness of deep learning in image classification. The structured approach taken in this project not only demonstrates the ability to automate digit recognition but also emphasizes the practical applications of neural networks in various industries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829c0c15-f6f7-442b-8dca-fadbd4293279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
